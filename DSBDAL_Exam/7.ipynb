{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e590b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac181494",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural Language Processing is the subfield of linguistic, computer science and artificial intelligence concerned with the interaction between human and computer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5406ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is the subfield of linguistic computer science and artificial intelligence concerned with the interaction between human and computer\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "filtered_text = re.sub(r'[^\\w\\s]','',text)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3b8186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'is', 'the', 'subfield', 'of', 'linguistic', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interaction', 'between', 'human', 'and', 'computer']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(filtered_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd1b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interaction', 'human', 'computer']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [x for x in tokens if x.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e469250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('subfield', 'VBD'), ('linguistic', 'JJ'), ('computer', 'NN'), ('science', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('concerned', 'VBN'), ('interaction', 'NN'), ('human', 'JJ'), ('computer', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = pos_tag(filtered_tokens)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa80e488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'subfield', 'linguist', 'comput', 'scienc', 'artifici', 'intellig', 'concern', 'interact', 'human', 'comput']\n"
     ]
    }
   ],
   "source": [
    "p = PorterStemmer()\n",
    "stem = [p.stem(x) for x in filtered_tokens]\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138fc3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interaction', 'human', 'computer']\n"
     ]
    }
   ],
   "source": [
    "l = WordNetLemmatizer()\n",
    "lemmatized_tokens = [l.lemmatize(x) for x in filtered_tokens]\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d07e36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(x):\n",
    "    if x.startswith('V'):\n",
    "        return 'v'\n",
    "    elif x.startswith('R'):\n",
    "        return 'r'\n",
    "    elif x.startswith('J'):\n",
    "        return 'a'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b52aa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concern', 'interaction', 'human', 'computer']\n"
     ]
    }
   ],
   "source": [
    "l = WordNetLemmatizer()\n",
    "lemma = [l.lemmatize(x,pos(w)) for x,w in pos_tagged]\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52610a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef1464cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" \".join(lemma)\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "tfidf_matrix = tv.fit_transform([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71e83a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial --->  0.2581988897471611\n",
      "computer --->  0.5163977794943222\n",
      "concern --->  0.2581988897471611\n",
      "human --->  0.2581988897471611\n",
      "intelligence --->  0.2581988897471611\n",
      "interaction --->  0.2581988897471611\n",
      "language --->  0.2581988897471611\n",
      "linguistic --->  0.2581988897471611\n",
      "natural --->  0.2581988897471611\n",
      "processing --->  0.2581988897471611\n",
      "science --->  0.2581988897471611\n",
      "subfield --->  0.2581988897471611\n"
     ]
    }
   ],
   "source": [
    "features = tv.get_feature_names()\n",
    "\n",
    "tfidf_score = dict(zip(features, tfidf_matrix.toarray()[0]))\n",
    "\n",
    "for word, score in tfidf_score.items():\n",
    "    print(f\"{word} --->  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241d561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Scores:\n",
      "Natural: -0.053319013889226566\n",
      "Language: -0.053319013889226566\n",
      "Processing: -0.053319013889226566\n",
      "subfield: -0.053319013889226566\n",
      "linguistic: -0.053319013889226566\n",
      "science: -0.053319013889226566\n",
      "artificial: -0.053319013889226566\n",
      "intelligence: -0.053319013889226566\n",
      "concerned: -0.053319013889226566\n",
      "interaction: -0.053319013889226566\n",
      "human: -0.053319013889226566\n",
      "computer: -0.10663802777845313\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# TF calculation\n",
    "tf = Counter(lemmatized_tokens)\n",
    "total_words = len(lemmatized_tokens)\n",
    "tf = {word: tf[word]/total_words for word in tf}\n",
    "\n",
    "# IDF calculation\n",
    "def calculate_idf(docs, term):\n",
    "    return math.log(len(docs) / (sum(1 for doc in docs if term in doc) + 1))\n",
    "\n",
    "idf = {word: calculate_idf([lemmatized_tokens], word) for word in set(lemmatized_tokens)}\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tfidf = {word: tf[word] * idf[word] for word in tf}\n",
    "\n",
    "print(\"TF-IDF Scores:\")\n",
    "for word, score in sorted(tfidf.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{word}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fcfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e35d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
